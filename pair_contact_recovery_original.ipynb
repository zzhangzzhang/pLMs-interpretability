{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d886348-6b7e-4e56-b01c-712c2fe182de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb416881-d2ad-4bdd-b126-b0614cf264d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import esm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import numpy as np \n",
    "import h5py\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd16a386-a5cb-4b13-9512-4c051f9e7592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "esm_transformer, esm2_alphabet = esm.pretrained.esm2_t36_3B_UR50D()\n",
    "batch_converter = esm2_alphabet.get_batch_converter()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "esm_transformer = esm_transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95032ff6-547d-46f6-86dd-892e4dc30b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_range_min = 50\n",
    "dist_range_max = 100 \n",
    "expand_type = 'outward' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1968c169-cd24-49f9-befa-1bd70596409c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_file_path = 'results/pair_' + str(dist_range_min) + '_' + str(dist_range_max) + '_' + expand_type + '_wbos_eos.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca1b194-298b-4530-9dde-6f846319eef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/ss_dict.json', \"r\") as json_file:\n",
    "    ss_dict = json.load(json_file)\n",
    "\n",
    "with open('data/full_seq_dict.json', \"r\") as json_file:\n",
    "    seq_dict = json.load(json_file)\n",
    "\n",
    "with open('data/selected_protein.json', 'r') as file:\n",
    "    selected_protein = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c864322d-ff34-49b4-92f7-64e999e22ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get all SSEs\n",
    "def get_segments(input_str):\n",
    "    segments = []\n",
    "    for match in re.finditer('E+|H+', input_str):\n",
    "        if (match.group()[0] == 'E' and len(match.group()) > 3) or \\\n",
    "           (match.group()[0] == 'H' and len(match.group()) > 7):\n",
    "            segments.append((match.start(), match.end()))\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09c559f-ee76-4af0-9692-50c0a149006d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def get_original_contact(seq): \n",
    "def get_contact(seq): \n",
    "    seq_tuple = [(1, seq)]\n",
    "    \n",
    "    # with BOS/EOS \n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(seq_tuple)\n",
    "    \n",
    "    # without BOS/EOS \n",
    "    #batch_tokens = torch.cat((torch.full((batch_tokens.shape[0], 1), 32), batch_tokens[:, 1:-1], torch.full((batch_tokens.shape[0], 1), 32)), dim=1)\n",
    "    \n",
    "    batch_tokens = batch_tokens.to(device)\n",
    "    with torch.no_grad():\n",
    "        esm2_predictions = esm_transformer.predict_contacts(batch_tokens)[0].cpu()\n",
    "    return esm2_predictions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012fa12f-0c5b-4639-82cf-a58a6f057af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get centers of SSEs \n",
    "def get_ss_cents(segments): \n",
    "    ss_cents = []\n",
    "    for seg in segments: \n",
    "        ss_cents.append((seg[1] + seg[0])//2) \n",
    "    return ss_cents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "babd63c3-76b6-476d-96d7-ed0b63ff0094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select pairs of SSEs separated by certain distance \n",
    "def get_pairs(arr):\n",
    "    pairs = []\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(i+1, len(arr)):\n",
    "            if dist_range_min < abs(arr[i] - arr[j]) <= dist_range_max: # look at long separation ones \n",
    "                pairs.append((arr[i], arr[j]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a186254-4576-4f13-9a26-7c612446e071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take 5 res on both sides \n",
    "# select segment pairs with enough contacts + leaves enough distances for exploring different flanking lengths \n",
    "def select_pairs(cent_pairs, matrix, cutoff, seq_len):\n",
    "    selected_pairs = []\n",
    "    for pair in cent_pairs: \n",
    "        ss1_start = pair[0] - 5 \n",
    "        ss2_end = pair[1] + 5 + 1 \n",
    "        patch_sum = np.sum(matrix[(pair[0] - 5): (pair[0] + 6), (pair[1] - 5): (pair[1] + 6)])\n",
    "        # check there is enough contact between the two SSE \n",
    "        # check there is enough region for expanding to check recovery \n",
    "        if (patch_sum > cutoff) and (min(ss1_start, seq_len - ss2_end - 1) > 10):\n",
    "            selected_pairs.append(pair) \n",
    "    n = min(len(selected_pairs), 3)\n",
    "    selected_pairs = random.sample(selected_pairs, n)\n",
    "    return selected_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20691fc2-5870-43fe-bace-39913e2b9708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the masked sequence and then the contact map \n",
    "def get_seg_contact(sequence, frag1_start, frag1_end, frag2_start, frag2_end): # flank_len is the amount of residues to add at sides of the segments  \n",
    "    seg_seq_i = sequence[frag1_start: frag1_end] \n",
    "    seg_seq_j = sequence[frag2_start: frag2_end] \n",
    "    mask_length = frag2_start - frag1_end \n",
    "    full_seq = frag1_start * '<mask>' + seg_seq_i + mask_length * '<mask>' + seg_seq_j + (len(seq) -  frag2_end) * '<mask>'\n",
    "    contact_map = get_contact(full_seq) \n",
    "    return contact_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92c1b007-8b12-4afd-a7fd-23cab372841f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm_sum_mult(ori_contact_seg, seg_cross_contact):\n",
    "    ori_mult_new = np.multiply(ori_contact_seg, seg_cross_contact)\n",
    "    ori_mult_ori = np.multiply(ori_contact_seg, ori_contact_seg)\n",
    "    return (np.sum(ori_mult_new)/np.sum(ori_mult_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b70b18-805b-4e65-9769-2c57e8f5581a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = ['3CKCA', '1PVGA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d85e4fbc-adfd-4af1-b340-a71a48f9d531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:20<00:20, 20.28s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:20<00:00, 10.26s/it]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(save_file_path, 'w') as f:\n",
    "    #for i, protein_name in enumerate(tqdm(selected_protein)):\n",
    "    for i, protein_name in enumerate(tqdm(test)):\n",
    "        seq = seq_dict[protein_name]\n",
    "        contact_ori = get_contact(seq) \n",
    "        ss = ss_dict[protein_name + '.pdb']\n",
    "        \n",
    "        segments = get_segments(ss)\n",
    "        ss_cents = get_ss_cents(segments)\n",
    "        ss_pairs = get_pairs(ss_cents)\n",
    "        selected_pairs = select_pairs(ss_pairs, contact_ori, 10, len(seq))\n",
    "        \n",
    "        for position in tqdm(selected_pairs):\n",
    "            ss1_start = position[0] - 5 \n",
    "            ss1_end = position[0] + 5 + 1 \n",
    "            ss2_start = position[1] - 5 \n",
    "            ss2_end = position[1] + 5 + 1 \n",
    "            \n",
    "            ori_contact_seg = contact_ori[ss1_start:ss1_end, ss2_start:ss2_end]\n",
    "            \n",
    "            #expand outward \n",
    "            flank_len_range = min(ss1_start, len(seq) - ss2_end - 1)\n",
    "            \n",
    "            for flank_len in range(flank_len_range):\n",
    "\n",
    "                    # expand outward \n",
    "                    frag1_start = ss1_start - flank_len\n",
    "                    frag1_end = ss1_end\n",
    "                    frag2_start = ss2_start\n",
    "                    frag2_end = ss2_end + flank_len\n",
    "\n",
    "                    seg_contact = get_seg_contact(seq, frag1_start, frag1_end, frag2_start, frag2_end) \n",
    "\n",
    "                    # expand both ways / outward / inward\n",
    "                    seg_cross_contact = seg_contact[ss1_start:ss1_end, ss2_start:ss2_end]\n",
    "\n",
    "                    sum_diff_value = np.sum(seg_cross_contact) - np.sum(ori_contact_seg)\n",
    "                    norm_sum_mult_value = norm_sum_mult(ori_contact_seg, seg_cross_contact)\n",
    "\n",
    "                    key1 = f'{protein_name}/{position[0]}_{position[1]}/{flank_len}/seg_contact' \n",
    "                    key2 = f'{protein_name}/{position[0]}_{position[1]}/{flank_len}/seg_cross_contact' \n",
    "                    key3 = f'{protein_name}/{position[0]}_{position[1]}/{flank_len}/sum_diff' \n",
    "                    key4 = f'{protein_name}/{position[0]}_{position[1]}/{flank_len}/sum_mult' \n",
    "\n",
    "                    f.create_dataset(key1, data=seg_contact)\n",
    "                    f.create_dataset(key2, data=seg_cross_contact)\n",
    "                    f.create_dataset(key3, data=sum_diff_value)\n",
    "                    f.create_dataset(key4, data=norm_sum_mult_value)\n",
    "        if i % 300 == 0:\n",
    "            f.flush()\n",
    "            shutil.copy(save_file_path, save_file_path.split('.')[0] + '_' + str(i) + '.hdf5')\n",
    "            time.sleep(20)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690c561-d510-402a-a26c-2d9b0967db1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "so_covar",
   "language": "python",
   "name": "so_covar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
